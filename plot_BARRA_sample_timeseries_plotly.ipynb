{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop demo 3\n",
    "Create an interactive timeseries plot of the 10-min surface level BARRA sample data at a given location using the plotly package.\n",
    "\n",
    "Nathan Eizenberg, Bureau of Meteorology, January 2018\n",
    "\n",
    "## Setting up environment\n",
    "\n",
    "Please refer to the instructions in the __[README.md](https://github.com/nathan-eize/AMOS2018-BARRA-data-demos/blob/master/README.md)__ for setting up the environment.\n",
    "\n",
    "## Finding the BARRA sample data\n",
    "This notebook uses ~100 netCDF files from the BARRA sample dataset, but will work with as many as you have in your ```dataDirRoot```, please define this accordingly. The full sample dataset is world readable (for the next few weeks only!) on the gdata1a filesystem at NCI, or you can download the files from our BOM public webpage.\n",
    "### Access NCI\n",
    "If you have any account to *any* project at NCI then you should be able to access the BARRA sample files - I have made the directories world readable for the AMOS workshop and for the next few weeks. Please find the sample data at the path ```/g/data/ma05/sample```. \n",
    "### Download via webpage\n",
    "We have recently added the sample dataset to our __[BoM Reanlysis webpage](http://www.bom.gov.au/research/projects/reanalysis)__. You can download the files directly but please note that this host is not intended for bulk downloads. If you are using more than 100 files please consider getting an account on NCI to view the data in situ. \n",
    "\n",
    "## Running the notebook \n",
    " 2. Ensure you are in conda environment '*analysis3-unstable*' or equivalent \n",
    " 2. Choose which model from the sample dataset with the ```model``` variable:\n",
    "     - *BARRA_R*, for the 12km, whole-of-Australia data assimilation system, or\n",
    "     - *BARRA_TA*, for the 1.5km, Tasmania-only downscaling system\n",
    "   \n",
    " \n",
    " 2. Define your ```dataDirRoot``` to the top directory containing the sample data files with the filestructure defined in the __[sample data ReadMe file](http://www.bom.gov.au/clim_data/rrp/BARRA_sample/ReadMe)__.\n",
    " 2. Run the entire notebook by choosing *Cell* --> *Run All*, from the Jupyter toolbar\n",
    " 4. Scroll to the bottom to view the interactive plot in the ultimate cell\n",
    " 5. Choose from the parameters on the left dropdown box to update the plot with the 24-hour timeseries of that parameter at the closest grid point of the given latitude and logitude coordinates\n",
    " 6. Play around with the input configurations, choosing from \n",
    "     ```model```, ```latInput``` and ```lonInput``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactively adjustable time series of multiple BARRA parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model of the sample data to plot\n",
    "model = 'BARRA_R' # either 'BARRA_R' or 'BARRA_TA'\n",
    "# define dirs of sample data\n",
    "dataDirRoot = '/g/data/ma05/sample'\n",
    "dataDirTemplate = os.path.join(dataDirRoot, '{model}/v1/{typeLong}/{stream}')\n",
    "# lat lons of UNSW Quaderangle Lawn\n",
    "latInput,lonInput = (-33.917089, 151.231058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules setup\n",
    "We make handy use of the following great libraries:\n",
    " * pandas, making tabular data simple https://pandas.pydata.org/\n",
    " * iris, for dealing with gridded data of different formats developed by the UK MetOffice http://scitools.org.uk/iris/, and\n",
    " * plot.ly, for powerful interactive graphing classes https://plot.ly/python/\n",
    "\n",
    "The plotly library is designed to create your plots online by default, however we will change this so that the plots are created only in this notebook. The ```plotly.offline``` methods copy the relevant plotly classes into the notebook and allow standalone, offline plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import cf_units as units\n",
    "iris.FUTURE.netcdf_promote = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built on plotly version 2.2.3 in the analysis3-unstable conda env\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly configuration to enable offline interactive plotting\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook tab completion to 'greedy'\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso 1806 time format string\n",
    "isoFormat = '%Y%m%dT%H%MZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_from_cube(cube, lonIdx,latIdx ):\n",
    "    \"\"\"\n",
    "    Returns a single pixel timeseries iris cube given a full iris cube and a lat lon index pair\n",
    "    \"\"\"\n",
    "    dimNameOrder = ['time','latitude','longitude']\n",
    "    dimNames = [ dc.standard_name for dc in cube.dim_coords ]\n",
    "    assert dimNameOrder == dimNames, \"Unexpected dimension list/order {:}\".format(dimNames)\n",
    "    return cube[slice(cube.coord('forecast_period').points.tolist().index(6.0) + 1), latIdx, lonIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ts_from_input_list( inSubList, latIn=latInput, lonIn=lonInput ):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of timeseries data from a list of netCDF consecutive filepaths of a single parameter\n",
    "        and a given latitude and logitude (degrees)\n",
    "    In:\n",
    "        inSubList - a list of BARRA sample netCDF files, these should be of a single paramater\n",
    "        latIn - float of latitude to choose closest North-South pixel, default global latInput\n",
    "        lonIn - float of longitude to choose closest East-West pixel, default global lonInput\n",
    "    Out:\n",
    "        dict(\n",
    "            tList - single list length N of datetime objects\n",
    "            dList - single list length N of float values of param timeseries at pixel\n",
    "            parStr - parameter string of cube\n",
    "            parLongname - parameter long name of cube\n",
    "            parUnit - iris cf unit object of physical units of parameter eg. m/s for windspeed\n",
    "            parAttr - dictionary of all file metadata for that parameter\n",
    "    \"\"\"\n",
    "    # get data\n",
    "    cubes = iris.load(inSubList)\n",
    "    # check that all parameters are the same\n",
    "    assert all(c.standard_name == cubes[0].standard_name for c in cubes[1:]), \"Not all cubes are same param\"\n",
    "    # get closest lat lon indices to input\n",
    "    lonXIdx = cubes[0].coord(standard_name = 'longitude').nearest_neighbour_index(lonIn)\n",
    "    latXIdx = cubes[0].coord(standard_name = 'latitude').nearest_neighbour_index(latIn)\n",
    "    # return timeseries from each cube into list\n",
    "    subCubes = [get_ts_from_cube(c, lonXIdx, latXIdx ) for c in cubes]\n",
    "    # convert times to datetime objects and into a single list\n",
    "    timeList = []\n",
    "    [timeList.extend(c.coord('time').units.num2date(c.coord('time').points).tolist()) for c in subCubes];\n",
    "    # and the data into a single list\n",
    "    datList = []\n",
    "    [datList.extend(c.data.tolist()) for c in subCubes];\n",
    "    return dict(\n",
    "        tList = timeList,\n",
    "        dList = datList,\n",
    "        parStr = cubes[0].standard_name,\n",
    "        parLongname = cubes[0].long_name,\n",
    "        parUnit = cubes[0].units,\n",
    "        parAttr = cubes[0].attributes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate files to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan through directory and create a dictionary of values:list_of_filepaths and key:parameter_string\n",
    "sampleFileDict = {}\n",
    "for root, dir, files in os.walk(dataDirTemplate.format(model=model, typeLong='forecast', stream='spec')):\n",
    "    # want all surface level files in the spec dir that aren't on tiled dimensions or accumulations\n",
    "    if 'accum' in root:\n",
    "        continue\n",
    "    if 'tiles' in root:\n",
    "        continue\n",
    "    if files == []:\n",
    "        continue\n",
    "    parStr = root.split('/')[-3] # grab the param\n",
    "    fList = [os.path.join(root, f) for f in files if f.endswith('.nc')]\n",
    "    fList.sort()\n",
    "    sampleFileDict[parStr] = fList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary should be completely populated, you can limit the plot scope at this point by \n",
    "#    trimming the dictionary\n",
    "sampleFileDict;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found {:d} params and a total of {:d} files\".format(len(sampleFileDict.keys()), \\\n",
    "            len([file for p, flist in sampleFileDict.items() for file in flist ])))\n",
    "print(\"List of unique params: \\n\\t{:}\".format('\\n\\t'.join(set(sampleFileDict.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out timeseries at given pixel and create data structures for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through sample data dict for each parameter, filter the single pixel timeseries\n",
    "#   and store in a dictionary of pandas series', and metadata info\n",
    "# THIS MAY TAKE 20-30 seconds to run!\n",
    "seriesDict = {}\n",
    "metaDict = {}\n",
    "for param, fList in sampleFileDict.items():\n",
    "    rDict = return_ts_from_input_list(fList)\n",
    "    seriesDict[param] = pd.Series(data=rDict['dList'], index=rDict['tList'], name=rDict['parStr'])\n",
    "    metaDict[param] = dict(\n",
    "        units = rDict['parUnit'],\n",
    "        attr = rDict['parAttr'],\n",
    "        longname = rDict['parLongname']  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And put series' into a single dataframe\n",
    "df = pd.DataFrame.from_dict(seriesDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictinary of data series for the plotly object, all the data are sitting in the single plot object,\n",
    "# we use the plotly 'update' method to select which data are visible based on interactive selection\n",
    "data = [go.Scatter(x=df.index, y=df[col], name=metaDict[col]['longname']) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interactive plot object uses an 'update' dictionary to change the configuration of the plot layout.\n",
    "# We create this dictionary in a loop for each of the dataframe columns, ie parameters. For each parameter\n",
    "# 'button' we only want that parameter to be visible\n",
    "buttonList = []\n",
    "for col in df.columns:\n",
    "    tmpDict = dict(\n",
    "        label = col,\n",
    "        method = 'update',\n",
    "        args = [\n",
    "            {'visible':[True if idx == df.columns.tolist().index(col) else False for idx in range(len(df.columns))]},\n",
    "            {'title':'Timeseries of {} at location lat,lon:({:2.2f},{:2.2f})'.format(col, latInput, lonInput)},\\\n",
    "            {'yaxis':{'title':\"{} [{}]\".format(col, str(metaDict[col]['units'])), 'visible':True}}\n",
    "        ]\n",
    "    )\n",
    "    buttonList.append(tmpDict)\n",
    "\n",
    "updatemenus = [dict(buttons=buttonList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the main layout of the plot and enable the update methods defined earlier \n",
    "layout = go.Layout(\n",
    "    title = 'Interactive timeseries plot for {} sample data at a chosen lat lon point'.format(model),\n",
    "    showlegend = True,\n",
    "    updatemenus=updatemenus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = dict(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iplot(fig)\n",
    "# Choose the paramater from the dropdown box on the left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
